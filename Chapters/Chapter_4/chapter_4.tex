\chapter{Polarised PDFs from DIS and SIDIS}
\label{ch:4}

In this Chapter, I present the first determination of polarised PDFs at next-to-next-to-leading order accuracy based on the MAP methodology, \texttt{MAPpol1.0}. The determination has been carried out including all available data from inclusive and semi-inclusive, neutral current, polarised DIS coming from different facilities. The final result is a determination of quark, antiquark, and gluon distributions at NNLO accuracy. In \secref{sec:4.1} I review the available data sets, and I discuss how pseudodata are generated in the context of the Monte Carlo method. The details of the QCD analysis are discussed in \secref{sec:4.2}. In \secref{sec:4.3} I review the fitting strategy and discuss how the methodology discussed in \chapref{ch:3} applies in the present work. Finally, the \texttt{MAPpol1.0} parton set is presented in \secref{sec:4.4}, where it is compared to other available sets. The stability of the results upon variation of data sets and theoretical constraints is also discussed.

\section{Experimental input}
\label{sec:4.1}

I review the experimental data sets used in the determination of the \texttt{MAPpol1.0} parton set, and I present how the experimental uncertainties are taken into account. A more detailed account of the construction of the ensemble through Monte Carlo method is also given.

\subsection{Data sets}
%%
\begin{figure}[t]
  \centering
  \includegraphics[width=1\textwidth]{kin_cov.png} 
  \caption{\small{Kinematic coverage in the $(x,Q^2)$ plane. The orange- and green-coloured areas represent the cuts in $Q^2$ and $W^2$, respectively.}}
  \label{fig:kin_cov}
\end{figure}
%%
The analysis makes use of inclusive and semi-inclusive lepton-nucleon DIS data coming from different facilities, CERN \cite{EuropeanMuon:1989yki, SpinMuon:1999udj, COMPASS:2006mhr, COMPASS:2010wkz, COMPASS:2010hwr}, SLAC \cite{E142:1996thl, E143:1998hbs, E154:1997xfa, E155:2000qdr}, DESY \cite{HERMES:2018awh, HERMES:2006jyl, HERMES:1997hjr} and Jefferson Lab \cite{Kramer:2002tt, JeffersonLabHallA:2004tea, CLAS:2014qtg}. For both DIS and SIDIS, the lepton beams are made of either electrons or muons. The targets are well approximated  by either protons or neutrons, and, in some case, deuterons. The main features of the data sets are summarised in Tabs.~[\ref{tab:DIS_data}, \ref{tab:SIDIS_data}], in which the number of data points, the kinematic coverage, and the measured observables are shown. The global kinematic coverage in the $(x,Q^2)$ plane is also displayed in Fig.~\ref{fig:kin_cov}. \par
Among the observables reconstructed in experiments, in this work I consider the inclusive and semi-inlcusive polarised structure functions, $g_1$ and $g_1^{(h)}$ respectively. However, some experiments normalise these observables with the unpolarised structure function, that is $g_1/F_1$ and $g_1^{(h)}/F_1^{(h)}$. In this case, the predictions require the computation of the unpolarised structure function $F_1$ and $F_1^{(h)}$ for each data point. %

In order to ensure the reliability of perturbative QCD, all data points with $Q^2 \leq Q^2_{\T{cut}} = 1 \, \T{GeV}^2$ are excluded. This cut corresponds to the orange-coloured area of Fig.~\ref{fig:kin_cov}. In addition, I also impose a cut on the squared invariant mass of the hadronic final state $W^2$, in order to remove all the points that may be affected by higher-twist corrections, as discussed in \secref{sec:field_theoretic}. In choosing the value for $W_{\T{cut}}$, I performed several fits with different values, that is $W_{\T{cut}}~=~1.0, \, 2.0, \, 2.5,$ and $3 \, \T{GeV}$. Although a small improvement of the fit quality (\textit{i.e.}, the global $\chi^2$ whose definition will be discussed later) is observed as the cut on $W$ is raised, the impact on helicity PDFs remains negligible. Thus, I chose to exclude points with $W^2~\leq~W^2_{\T{cut}}~=~6.5~\T{GeV}^2$ (green area in Fig.~\ref{fig:kin_cov}), which is a good compromise between the number of surviving points and the fit quality.%

%The resulting kinematic coverage is highly affected by the cuts. Starting from $480$ initially available points, after cuts this number reduces to $N_{\T{dat}}=360$,  -- a reduction of about $25\%$ respect to the initial availability. It can be observed that the most affected experiments are those performed by Jefferson Lab \cite{Kramer:2002tt, JeffersonLabHallA:2004tea, CLAS:2014qtg}. Indeed, the cut in $W^2$ mainly affects all data points that cover the large-$x$ and small-$Q^2$ corner, which is exactly the region probed by these experiments.%

Although the coverage of both low- and large-$x$ regions have been improved in recent years, the present situation for polarised data is not comparable with the unpolarised counterpart. The latter provides over than $3000$ data points coming from different processes in addition to DIS (see \textit{e.g}, Ref.~\cite{Kassabov:2022pps}). Moreover, the precision of unpolarised measurements is generally better if compared to the polarised case. Still, this does not prevent us to perform a global determination, provided a reliable estimation of the uncertainties.%

For each observable listed in Tabs.~[\ref{tab:DIS_data},\ref{tab:SIDIS_data}], various pieces of information are available, although, in some cases, they are incomplete. In particular, correlated systematics (multiplicative and/or additive) are only given by E143, E155, EMC, and HERMES, whereas the other experiments provide uncorrelated uncertainties only. The experimental covariance matrix $V_{ij}$ is constructed as follows
%%
\begin{equation}
  V_{ij} =  \sigma_{i,\T{unc}} \sigma_{j,\T{unc}} \delta_{ij} + \sum_{\ell=1}^{l} \sigma_{i,\T{corr}}^{(l)} \sigma_{j,\T{corr}}^{(\ell)} \,,
  \label{eq:covariance_matrix}
\end{equation}
%%
where $i$ and $j$ run over the experimental data points, $\sigma_{i,\T{corr}}^{(\ell)}$ are the various sources of correlated uncertainties, and $\sigma_{i,\T{unc}}$ are the uncorrelated uncertainties. The latter are defined as the sum in quadrature of all uncorrelated sources of statistical $\sigma_{i,\T{stat}}$ and systematic $\sigma_{i,\T{syst}}$ uncertainties for the $i$-th point
%%
\afterpage{
\begin{landscape}% Landscape page
  \begin{table}
  \scriptsize
  \centering % Center table
  \input{tables/DIS_data.tex}
  \caption{
    \small
    Experimental DIS data sets included in the \texttt{MAPpol1.0} analysis. For each experiment, the number of data points before and after (in parentheses) applying kinematic cuts, the covered kinematic range and the measured observables are shown.
  \label{tab:DIS_data}}% Add 'table' caption
  \end{table}
\end{landscape}}
%%
\afterpage{
\begin{landscape}% Landscape page
  \begin{table}
  \scriptsize
  \centering % Center table
  \input{tables/SIDIS_data.tex}
  \caption{
    \small
    Experimental SIDIS data sets included in the \texttt{MAPpol1.0} analysis. For each experiment, show the number of data points before and after (in parenthesis) applying kinematic cuts, the covered kinematic range and the measured observables are shown.
  \label{tab:SIDIS_data}}% Add 'table' caption
  \end{table}
\end{landscape}}
%%
\begin{equation}
  \sigma_{i,\T{unc}}^2 = \sigma_{i,\T{stat}}^2 + \sigma_{i,\T{syst}}^2 \,.
\end{equation}
%%
Finally, the first moments of the non-singlet triplet and octet distributions, $a_3$ and $a_8$, are treated as two additional data points that enter the computation of the $\chi^2$. The values, measured from the hyperon $\beta$-decay, are \cite{Nakamura_2010}
%%
\begin{equation}
  a_3 = 1.2701 \pm 0.0025 \hspace{10mm} a_8 = 0.585 \pm 0.025 \,.
  \label{eq:a3_a8_values}
\end{equation}
%%
I will further discuss these two points in \secref{sec:4.3}.

\subsection{Generation of Monte Carlo replicas}
\label{sec:gen_MC}
In order to propagate the error from experimental data, I use the Monte Carlo sampling method discussed in \secref{sec:MAP}. The artificial points are obtained by sampling the distributions of experimental data, obtaining an ensemble of $N_{\T{rep}}$ replicas that reflect the statistical properties of the original data set.%

The key point to observe is that the fluctuated points must follow the same distribution of the unfluctuated data. I assume data to be distributed according to a multi-variate Gaussian distribution, whose mean values correspond to the experimental central points and the covariance matrix is constructed as in Eq.~\eqref{eq:covariance_matrix}. The $\chi^2$ obtained by comparing the unfluctuated central value $m_j$ with its fluctuated value $f_j$, expressed in matrix form, must then read
%%
\begin{equation}
  \chi^2 = \tran{\vb*{d}} \cdot \vb*{V}^{-1} \cdot \vb*{d} \,,
  \label{eq:chi_fluc}
\end{equation}
%%
where $\vb*{V}$ is the usual $N_{\T{dat}} \times N_{\T{dat}}$ covariance matrix and $\vb*{d}$ is a column vector with $N_{\T{dat}}$ entries defined as
%%
\begin{equation}
  d_j = f_j - m_j \,.
\end{equation}
%%
On the other hand, the $\chi^2$ is also defined as
%%
\begin{equation}
  \chi^2 = \sum_{i=1}^{N_{\T{dat}}} z_i^2 = \left| \vb*{z} \right|^2 \,,
  \label{eq:chi2_normal}
\end{equation}
%%
where $z_j$ are independent, standard normal random variables such that
%%
\begin{equation}
  \langle z_i \rangle = 0 \hspace{10mm} \T{and} \hspace{10mm}  \langle z_i z_j \rangle = \delta_{ij} \,.
\end{equation}
%%
It immediately follows that $\langle \chi^2 \rangle = N_{\T{dat}}$, as predicted by the $\chi^2$ distribution. Now, the covariance matrix, being a symmetric object, admits the so-called Cholesky decomposition, that allows us to write
%%
\begin{equation}
  \vb*{V} = \vb*{L} \cdot \tran{\vb*{L}} \,,
\end{equation}
%%
where $\vb*{L}$ is a lower diagonal matrix\footnote{Further details on the Cholesky decomposition can be found in Appendix \ref{app:lin_sys}.}. Thus, the $\chi^2$ in Eq.~\eqref{eq:chi_fluc} can be recast as
%%
\begin{equation}
  \chi^2 = \left| \vb*{L}^{-1} \cdot \vb*{d} \right|^2 \,.
  \label{eq:chi2_Cholesky}
\end{equation}
%%
Collecting Eqs.~\eqref{eq:chi2_Cholesky} and \eqref{eq:chi2_normal}, one finally obtains the following relation
%%
\begin{equation}
  f_j = m_j + \sum_{i=1}^{N_{\T{dat}}} L_{ji} z_i\,.
  \label{eq:MC_gen}
\end{equation}
%%
I stress that the above expression has been obtained by imposing that the fluctuated data followed the multi-variate Gaussian distribution and that the $\chi^2$ had the correct distribution. Thus, in order to generate an artificial value $f_j$, one has to use Eq.~\eqref{eq:MC_gen}, where $z_j$ is randomly extracted from a centred, univariate Gaussian distribution.\par
It is straightforward to show that the fluctuations generated according to Eq.~\eqref{eq:MC_gen} present the same statistical properties of the original data set. In particular, one can show that
%%
\begin{gather}
  \langle f_j \rangle = m_j \,,\\
  \langle f_j f_k \rangle = \langle f_j \rangle \langle f_k \rangle + V_{jk} \,,
\end{gather}
%%
which are the expected relations for a correct generation of a Monte Carlo ensemble.

%
\afterpage{
  \begin{figure}[t]
    \centering
    \includegraphics[width=1\textwidth]{replica_number.png} 
    \caption{\small{Scatter plots of experimental versus artificial Monte Carlo mean central values and absolute uncertainties of observables corresponding to Tabs.~(\ref{tab:DIS_data}, \ref{tab:SIDIS_data}) computed from ensembles made of $N_{\T{rep}} = 10$, $100$, $1000$ replicas.\\}
    \vspace{1cm}}
    \label{fig:replica_number}
  \end{figure}
  %%
  \begin{table}[b]
    \scriptsize
    \centering % Center table
    \input{tables/PE.tex}
    \caption{
      \small
      Table of statistical estimators for the percentage error and the scatter correlation $r$, Eqs.~(\ref{eq:PE}, \ref{eq:r}), computed from the Monte Carlo sample with $N_{\T{rep}}=10,\, 150,\, 1000$ replicas.
    \label{tab:PE}}% Add 'table' caption
  \end{table}
  \clearpage
}
%
The number of replicas is chosen in order to faithfully reproduce the statistical estimators of the original experimental data. For instance, one can check if the averages and the variances of the replica sample, that is
%%
\begin{equation}
  \langle F_{i}^{\T{(art)}} \rangle = \frac{1}{N_{\T{rep}}} \sum_{k=1}^{N_{\T{rep}}} F_{i}^{(k)} \hspace{5mm} \T{and} \hspace*{5mm} \sigma_i^{\T{(art)}} = \sqrt{ \langle \left( F_{i}^{\T{(art)}} \right) \rangle - \langle F_{i}^{\T{(art)}} \rangle^2} \,,
\end{equation}
%%
reproduce the experimental central values and the uncertainties of the original data set. Such a comparison is shown in Fig.~\ref{fig:replica_number}, where I display scatter plots of the central values and errors for samples of $N_{\T{rep}} = 10$, $150$ and $1000$ replicas. Although they only provide a qualitative description, they clearly show that the accuracy of the artificial sample increases with the size of the Monte Carlo sample. A more quantitative description can be carried out by defining appropriate statistical estimators. Following Ref.~\cite{DelDebbio:2004xtd}, I make use of the percentage error and the scatter correlation $r$ for central values, whose definitions are
%
\begin{gather}
  \left< PE \left[ \left< F^{(\T{art})} \right>_{\T{rep}} \right] \right>_{\T{dat}} = \frac{1}{N_{\T{dat}}} \sum_{i=1}^{N_{\T{dat}}} \frac{\abs{\left< F_i^{\T{(art)}} \right>_{\T{rep}} - F_{i}^{\T{(exp)}}}}{F_i^{\T{(exp)}}}\,, 
  \label{eq:PE}\\
  r \left[ F^{\T{(art)}} \right] = \frac{\left< F^{\T{(exp)}} \left< F^{\T{(art)}} \right>_{\T{rep}} \right>_{\T{dat}} - \left< F^{\T{(exp)}} \right>_{\T{dat}} \left<  \left< F^{\T{(art)}} \right>_{\T{rep}}\right>_{\T{dat}} }{\sigma_s^{\T{(exp)}} \sigma_s^{\T{(art)}} }\,,
  \label{eq:r}
\end{gather}
%%
where the scatter variances are defined as
%%
\begin{gather}
  \sigma^{\T{(exp)}}_s = \sqrt{\left< \left( F^{\T{(exp)}} \right)^2 \right>_{\T{dat}} - \left( \left< F^{\T{(exp)}} \right>_{\T{dat}} \right)^2} \,,\\
  %
  \sigma^{\T{art}}_s = \sqrt{\left< \left( \left<F^{\T{(art)}}\right>_{\T{rep}} \right)^2 \right>_{\T{dat}} - \left( \left< \left<F^{\T{(art)}}\right>_{\T{rep}} \right>_{\T{dat}} \right)^2} \,.
\end{gather}
%%
Essentially, the percentage error describes how well the central values are recovered by the Monte Carlo sample. On the other hand, the scatter correlation $r$ reflects the capacity of the Monte Carlo sample to reproduce the correlations that are present in the original data set. For each experiment, I show these two values for the observables $g_1^{(h)}$ and $g_1^{(h)}/F_1^{(h)}$ in Tab.~\ref{tab:PE}. The Monte Carlo sample with size $N_{\T{rep}} = 150$ gives a satisfactory reproduction of mean values and uncertainties of experimental data. The improvements obtained by using a larger sample are moderate, and, in any case, do not justify the higher computational effort. For these reasons, I will henceforth adopt ensembles with $N_{\T{rep}} = 150$ replicas as the standard configuration for the presented fits.

%_________________________________
\section{Details of the QCD analysis}
\label{sec:4.2}
Here I summarise the aspects concerning the QCD analysis of polarised structure functions. The main observables used throughout the analysis are the structure functions $g_1$, Eq.~\eqref{eq:g1_QFT}, and $g_1^h$, Eq.~\eqref{eq:g1h}, for DIS and SIDIS respectively.%

On the one hand, data coming from DIS experiments constrain only the linear combination of $\Delta \Sigma$, $\Delta T_3$, $\Delta T_8$, together with $\Delta g$, as it can be easily seen from Eq.~\eqref{eq:g1_NPM_ev}. On the other hand, SIDIS data provides full flavour separation. Moreover, given that data with kaons in the final state are given, it is possible to constrain the strange distributions $\Delta s$ and $\Delta \bar{s}$. In both SIDIS and DIS processes, the gluon distribution $\Delta g$ is weakly constrained. Indeed, it enters at NLO and its effect is suppressed by the running coupling. Processes other than those I have just discussed (such as jet or semi-inclusive production in proton-proton collisions), receiving LO contributions from gluon initiated subprocesses, may provide direct information on the gluon distribution \cite{Rojo:2015acz}.%

The proton, neutron, and deuteron PDFs are related to each other by isoscalarity (assumed as an exact symmetry) so that
%%
\begin{equation}
  \begin{split}
    &\Delta u^{(I)} = I \Delta u^p + ( 1 - I ) \Delta d^p \\
    &\Delta d^{(I)} = I \Delta d^p + ( 1 - I ) \Delta u^p
  \end{split}
  \label{eq:iso_rel}
\end{equation}
%%
where $I=1$, $0.5$ and $0$ representing proton, deuteron, and neutron respectively. A similar relation also holds for antiquark distributions. I will henceforth assume that PDFs refer to the proton.%

Intrinsic heavy quark distributions are automatically set to zero below the corresponding quark masses, that is $m_c=1.51\, \T{GeV}$ and $m_b=4.92\, \T{GeV}$. Over these thresholds, heavy quark distributions are generated perturbatively by means of the DGLAP equations, Eqs.~\eqref{eq:DGLAP_coupled}. The value for the strong coupling constant has been set to $\alpha_s(M_Z^2) = 0.118$.%

Finally, the computation of SIDIS observables requires the introduction of fragmentation function sets. For this analysis, I make use of the pion and kaon sets \texttt{MAPFF1.0}~\cite{Khalek:2021gxf, AbdulKhalek:2022laj}. These are obtained from a global analysis of unpolarised single-inclusive annihilation (SIA) and SIDIS data, with accuracy up to NNLO.

\section{Fitting configuration}
\label{sec:4.3}
In this section, I give the details of the fitting configuration adopted in the \texttt{MAPPol1.0} analysis. I discuss how the distributions are parametrised in terms of a neural network. Then, I will move to the description of the training procedure, providing a more detailed picture than that given in \secref{sec:NNtr}. In particular, I will describe the difference between the error function, used during the minimisation, and the global $\chi^2$, used to assess the fit quality. Finally, I review the theoretical constraints assumed in the analysis and their implications.

\subsection{Parametrisation}
The seven independent distributions that are determined through the analysis are $\Delta u, \, \Delta d, \, \Delta s, \, \Delta \bar{u}, \, \Delta \bar{d}, \, \Delta \bar{s}$ and $\Delta g$. These distributions are parametrised in terms of a single multi-layer feed-forward neural network, whose output layer is composed of seven differential nodes, one for each distribution. The PDFs are parametrised at an initial scale $\mu_0 = 1\,\T{GeV}$, below the heavy quark thresholds. The output of the network is then evolved to the experimental scale by means of the DGLAP equations, Eq.~\eqref{eq:DGLAP_coupled}.
%It has been observed that the variation of the initial scale up to $\mu_0 = 1.5\,\T{Gev}$ does not enhance the fit quality and the impact on PDFs is moderate. Higher values of the initial scale have not been considered, since heavy quark distributions would no longer be negligible.%

The architecture of the neural network is 1-10-6, which introduces 86 free parameters. I explicitly verified the parametrisation to be redundant enough to ensure that the results do not depend on the architecture. Indeed, keeping on the single deep-layer structure, I have not observed any considerable difference in the results by either increasing the nodes of the internal layer up to 20 or reducing this number to 5. Thus, an architecture with 10 internal nodes is a good compromise between the number of parameters and the redundancy in the parametrisation, which is enough to reproduce any functional form given sufficient training time.%

The single node in the input layer corresponds to the Bjorken variable $x$, while all the internal nodes of the neural network are activated by the sigmoid function, Eq.~\eqref{eq:sigmoid}. The output nodes are also activated by the sigmoid function, but it has been shifted and scaled to account for the positivity constraint, as I will further discuss later.%
 
The outputs of the network (\textit{i.e.}, the PDFs) are put on a grid in the $(x,Q^2)$ plane and then evolved by means of the DGLAP equations, Eqs.~\eqref{eq:DGLAP_coupled}. A schematic representation of the fitting algorithm is sketched in Fig.~\ref{fig:NN_plot}.
%%
\begin{figure}[t]
  \centering
  \includegraphics[width=1\textwidth]{NN_plot2.pdf} 
  \caption{\small{Scheme of the \texttt{Denali} algorithm.}}
  \label{fig:NN_plot}
\end{figure}
%%

\subsection{Optimisation}
\label{sec:optimisation}

For each $k$-th replica, parameters are optimised by minimising the figure of merit defined as
%%
\begin{equation}
  E^{(k)} = \frac{1}{N_{\T{dat}}} \sum_{i,j}^{N_{\T{dat}}} \left( O_{i}^{\T{(art)}(k)} - O_{i}^{\T{(net)}(k)} \right) (\T{cov})^{-1}_{ij} \left( O_{j}^{\T{(art)}(k)} - O_{j}^{\T{(net)}(k)} \right) \,.
  \label{eq:EF_k}
\end{equation}
%%
Here, $O_i$ represents one of the observable presented in Tabs.~(\ref{tab:DIS_data},\ref{tab:SIDIS_data}). The above expression requires a few comments. The observable $O_{i}^{\T{(art)}(k)}$ is the $k$-th Monte Carlo replica of the $i$-th data point, whereas $O_{i}^{(\T{net})(k)}$ is its prediction provided by the $k$-th neural network representing the corresponding replica of the PDF ensemble. Finally, $\T{(cov)}$ is the usual covariance matrix constructed from the experimental sets. The parameter space is explored with the SGD method discussed in \secref{sec:NNtr}, which seeks the minimum of the error function, Eq.~\eqref{eq:EF_k}.%

The error function, Eq.~\eqref{eq:EF_k}, must not be confused with the $\chi^2$ used to quantify the quality of the fit, which is defined as
%%
\begin{equation}
  \chi^2 = \frac{1}{N_{\T{dat}}} \sum_{i,j}^{N_{\T{dat}}} \left( O_{i}^{\T{(exp)}} - \left<O_{i}^{\T{(net)}}\right>_{\T{rep}} \right) (\T{cov})^{-1}_{ij} \left( O_{j}^{\T{(exp)}} - \left<O_{j}^{\T{(net)}}\right>_{\T{rep}} \right) \,,
  \label{eq:global_chi2}
\end{equation}
%%
where $O_{i}^{\T{(exp)}}$ is the $i$-th experimental central value and the average over replicas is computed as follows
%%
\begin{equation}
  \left< O_i^{\T{(net)}} \right>_{\T{rep}} = \frac{1}{N_{\T{rep}}} \sum_{k} O^{(k)}_i \,.
\end{equation}
%%
I will refer to Eq.~\eqref{eq:global_chi2} as the global $\chi^2$ per data point (or simply $\chi^2$). It is computed at the end of the optimisation procedure and, thus, it is not minimised.\footnote{\footnotesize It is worth mentioning that while the mean value of the global $\chi^2$ is $1$ in case of perfect data, that of the error function is $2$, as shown in Appendix~\ref{app:exp_err_func}. The reason for this shift is that in the figure of merit used in the minimisation, Eq.~\eqref{eq:EF_k}, the prediction is compared against the fluctuated data and not against the experimental central value.}%

As discussed at the end of \secref{sec:NNtr}, the neural network parametrisation, in principle, is able to fit not only the underlying physics, but also statistical noise of the data set -- a problem also known as \textit{overlearning}. Thus, the best fit does not always coincide with the minimum of the figure of merit, Eq.~\eqref{eq:EF_k}. In order to find the best fit, the cross-validation method \cite{pml1Book} is implemented. It works as follows:
%%
\begin{enumerate}
  \item For each replica, the data sets are randomly divided into two sets -- training and validation sets. They include a fraction $f_{\T{tr}}$ and $f_{\T{val}} = 1 - f_{\T{tr}}$ of the data points, respectively.
  \item During the optimisation procedure, the error function, Eq.~\eqref{eq:EF_k}, is separately computed over the training and the validation set. The former undergoes the minimisation procedure, while the latter is only monitored and not minimised.
  \item Finally, the best fit corresponds to the minimum of the error function of the validation set within a fixed number of iterations, which in this case corresponds to $N_{\T{iter}} = 3000$. It has been explicitly verified, by means of plots such as Fig.~\ref{fig:profile}, that the minimum did not occur after this number.
\end{enumerate}
%%
The profile of the figure of merit for an arbitrary replica is shown in Fig.~\ref{fig:profile}. It is possible to see that, immediately after the minimum of the validation curve is reached, it starts to increase, whereas the training curve keeps reducing. This means that the network is learning the statistical noise of the training set, which is different from that of the validation set. In this analysis, equal training and validation fractions are chosen, that is $f_{\T{tr}} = f_{\T{val}} = 50\%$. However, some experimental sets are highly affected by the kinematic cuts and only a small portion of data points survives. In this case, the training set would be too small, affecting the stability of the minimisation. Hence, if the number of points after cuts is less or equal to 5, all the points are included in the training set.

%%
\begin{figure}[t]
  \centering
  \includegraphics[width=0.6\textwidth]{profile.pdf} 
  \caption{\small{Profile of the error function for the 36th replica. The blue and red curves represent the error as a function of the iteration step for the training and validation sets, respectively.}}
  \label{fig:profile}
\end{figure}
%%

\subsection{Theoretical constraints}
I have already mentioned that, due to the scarcity and the low accuracy of data, polarised PDFs are loosely constrained. Not only does it affect the efficiency of the algorithm, but has a huge impact on the precision of the fit. In order to improve the constraining power and to reduce the uncertainties of the polarised PDFs, I apply two theoretical constraints to the analysis -- sum rules and positivity.%

Sum rules refer to the hadronic matrix elements $a_3$ an $a_8$, whose values can be extracted from measurements in hyperon $\beta$-decay, Eqs.~\eqref{eq:a3_a8_values}. They can be related to the PDFs via Eqs.~(\ref{eq:a3_PM}-\ref{eq:a8_PM}), provided that exact $SU(2)_f$ and $SU(3)_f$ symmetries are assumed. The theoretical constraint is introduced at data set level. This means that the values in \eqref{eq:a3_a8_values} are treated as standard data points, with central values and (uncorrelated) uncertainties. Hence, at each iteration of the optimisation procedure, the algorithm computes, in addition to the observables listed in Tabs.~\ref{tab:DIS_data} and \ref{tab:SIDIS_data}, the predictions for $a_3$ and $a_8$ via Eqs.~(\ref{eq:a3_PM}-\ref{eq:a8_PM}). Sum rules provide further information on polarised PDFs. If the SIDIS data sets were not included, the only source of information for the strange combination $\Delta s^+$ would only come from this theoretical constraint.%

The other theoretical constraint is the positivity constraint. The key point is that the cross-sections that enter the polarised asymmetry, Eq.~\eqref{eq:asymmetry}, must be positive. This implies that $g_1$ and $g_1^{(h)}$ are bound by their unpolarised counterpart $F_1$ and $F_1^{(h)}$, that is
%%
\begin{equation}
  \begin{split}
    \left| g_1 (x,Q^2)  \right|& \leq F_1(x, Q^2) \,,\\
    \left| g_1^{(h)} (x,z,Q^2)  \right|& \leq F_1^{(h)}(x, z, Q^2) \,.
  \end{split}
  \label{eq:positivity_obs}
\end{equation}
%%
Given that at leading order the structure functions are proportional to parton distributions, and that Eq.~\eqref{eq:positivity_obs} must be satisfied for any choice of target (\textit{i.e.}, for any combination of quark plus antiquarks), it must be satisfied by each flavour separately. Hence, at leading order, the bound reads
%%
\begin{equation}
  \left| \Delta f_i (x,Q^2) \right| \leq f_i (x,Q^2) \,,
  \label{eq:positivity_fl}
\end{equation}
%%
for all $x$ and for all $Q^2$, being $f_i$ the relative unpolarised PDF set. At NLO and beyond the positivity constraint, Eq.~\eqref{eq:positivity_fl}, receives perturbative corrections. Nevertheless, it can be shown \cite{Altarelli:1998gn} that, even at relatively small values of $Q^2 \sim 1 \, \T{GeV}^2$, positivity bounds for each flavour are slightly modified, and the difference between LO and higher orders is negligible. Moreover, the positivity bound exhibits its constraining effects only at large $x$, where the higher order corrections to the LO positivity bound are suppressed. Thus, imposing positivity bounds consistently guarantees positivity of physical cross-sections.%

The positivity bound Eq.~\eqref{eq:positivity_fl} must take into account the uncertainties of the unpolarised PDFs. This problem can be addressed with two different methods. The first imposes the leading-order bound, Eq.~\eqref{eq:positivity_fl}, by requiring
%%
\begin{equation}
  \left| \Delta f_i (x,Q^2) \right| \leq \left<f_i (x,Q^2)\right>_{\T{rep}} + \sigma_i(x,Q^2) \,,
  \label{eq:positivity_fl_sigma}
\end{equation}
%%
where $\left<f_i (x,Q^2)\right>_{\T{rep}}$ is the mean value over the statistical ensemble of unpolarised PDFs and $\sigma_i(x,Q^2)$ is its corresponding one-sigma uncertainty, both evaluated at the kinematic point $(x,Q^2)$. This ensures that also the uncertainty of the unpolarised distribution is propagated through the analysis within the confidence level. The second approach applies the same bound Eq.~\eqref{eq:positivity_fl}, but with a randomly chosen replica from the statistical set of distributions
%
\begin{equation}
  \left| \Delta f_i (x,Q^2) \right| \leq f_i^{(k)} (x,Q^2)\,, \hspace{4mm} k \hspace{2mm} \T{random}.
  \label{eq:positivity_random}
\end{equation}
%%
This means that the unpolarised PDF replica that enters the constraint is different for each polarised replica. This stocasticity spans the space of distributions, propagating the uncertainties of the unpolarised statistical ensemble through the bound.%

In both methods, consistency requires that the unpolarised parton set used to impose the positivity bound is the same that has been used to compute the unpolarised structure functions $F_1$ and $F_1^{(h)}$, when required by the data set (see Tabs.~\ref{tab:DIS_data} and \ref{tab:SIDIS_data}).%

The positivity constraint is implemented analytically, acting on the output layer of the neural network. Indeed, for each node of the last layer (\textit{i.e.}, for each parametrised flavour), I impose
%%
\begin{equation}
  \sigma_{i} (x,\mu_0) \rightarrow \Delta f_{i} (x, \mu_0) \equiv \bigl[ 2 \sigma(x,\mu_0) - 1 \bigr] \, f_{i} (x,\mu_0) \,,
  \label{eq:pos_net}
\end{equation}
%%
being $\sigma_i(x,\mu^2_0)$ the sigmoid activation function of the $i$-th output of the network. We observe that Eq.~\eqref{eq:pos_net} not only imposes the positivity bound Eq.~\eqref{eq:positivity_fl}, but also constrains parton distribution to zero at $x=1$, provided that the unpolarised PDF is zero at the same point. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}
\label{sec:4.4}

\begin{table}[t]
  \centering 
  \small
  \input{tables/baseline_configuration.tex}
  \caption{
    \small
    Fitting configuration of baseline setting of the \texttt{MAPpol1.0} set.
  \label{tab:baseline}}
\end{table}

In this section, I present the first determination of polarised PDFs \texttt{MAPpol1.0} obtained at next-to-next-to-leading order accuracy. It relies on the methodology that has been exposed earlier and includes the data sets introduced in \secref{sec:4.1}. The parton distributions have been parametrised at an initial scale $\mu_0 = 1\,\T{GeV}$, below the heavy quark mass thresholds.%

The unpolarised set of parton distribution functions used to compute the unpolarised structure functions $F_1$ and $F_1^{(h)}$ and to impose the positivity constraint (see later) is \texttt{NNPDF31\_nnlo\_pch\_as\_0118}~\cite{NNPDF:2017mvq}, while the set of FFs necessary to compute the SIDIS observables is \texttt{MAPFF1.0}~\cite{Khalek:2021gxf, AbdulKhalek:2022laj}. This fitting configuration, which is summarised in Tab.~\ref{tab:baseline}, represents the default set-up, and I will refer to it as the \textit{baseline} configuration.%

First, I present the \texttt{MAPpol1.0} set and its statistical features. The impact of higher order corrections is discussed and compared with the NLO determination obtained with the same fitting configuration. Then, I review the impact of the theoretical constraints and assess the stability of the results by performing a number of variations w.r.t. the baseline setting and the original data set presented before. Finally, I compare the \texttt{MAPpol1.0} set with other available sets, focusing on the main differences that arise among them.

%__________________________________________________
\subsection{Impact of NNLO corrections}
\label{sec:nnlo}

The NNLO and NLO determinations obtained with the baseline set-up are presented in Fig.~\ref{fig:nnlo_nlo}. The values of the $\chi^2$ per data point computed with Eq.~\eqref{eq:global_chi2} are displayed in Tab.~\ref{tab:nnlo_nlo_chi2} for each data set included in the analysis. The values for the global data set are also shown, which amount to $0.66$ and $0.82$ for the NLO and NNLO determinations, respectively. This indicates a general good description of the entire data set for both fits. A closer inspection of Tab.~\ref{tab:nnlo_nlo_chi2} reveals that a good description is achieved for all individual data sets. In the case of JLAB data, the smallness of the $\chi^2$ is due to the fact that only a very small number of experimental points survives kinematic cuts (see Tab.~\ref{tab:DIS_data}), and hence it is not statistically significant.%

The discrepancy between the two values of the global $\chi^2$ at NLO and NNLO seems to indicate that the global agreement between data and the central replica is worse for the NNLO case. Moreover, similar deteriorations of the fit quality show up in some SIDIS measurements (in particular those coming from HERMES) and in the sum rule $a_3$, as it can be seen from Tab.~\ref{tab:nnlo_nlo_chi2}. These early observations will be further analysed in Sec.~\ref{sec:study_data}, where I will discuss the impact of some changes in data sets on the discrepancy of the global $\chi^2$ between the two perturbative orders.

\afterpage{
  \begin{table}
    \centering % Center table
    \small
    \input{tables/chi2_nnlo_nlo.tex}
    \caption{
      \small
      Values of the $\chi^2$ per data point computed with Eq.~\eqref{eq:global_chi2} for the individual data sets included in the \texttt{MAPpol1.0} analysis for NNLO and NLO distributions. The global $\chi^2$ values are also displayed.
      \label{tab:nnlo_nlo_chi2}}% Add 'table' caption
  \end{table}
  \clearpage}
  
\afterpage{
  \begin{figure}
    \centering
    \includegraphics[width=\textwidth]{Chapters/Chapter_4/figs/nnlo_nlo_ratio_sbar.pdf}
    \caption{\small Comparison between the NNLO and NLO \texttt{MAPpol1.0} sets at $\mu_0 = 1 \, \T{GeV}$ in flavour basis and plotted as functions of $x$. For each flavour, the absolute values of the distributions are displayed in the upper panel and their ratio to the central value of the NNLO fit in the lower one. Uncertainties correspond to $1 \, \sigma$.}
    \label{fig:nnlo_nlo}
  \end{figure}
  \clearpage}


In the case of the gluon distribution $\Delta g$, the differences are mostly in terms of precision. On the one hand, the uncertainty is considerably smaller for the NNLO fit, in particular in the region $0.003 \lesssim x \lesssim 0.04$. On the other hand, the central value remains almost stable with small differences in central-$x$ region. Still, it must be remarked that the gluon distribution remains poorly constrained by data, and the inclusion of different processes other than those included in this analysis may considerably change the behaviour of the gluon.%

The impact of NNLO corrections on valence quark distributions $\Delta u$ and $\Delta d$ is moderate. In particular, the $\Delta u$ distributions are in perfect agreement in terms of both precision and accuracy, whereas the central value of $\Delta d$ receives a small upward shift at NNLO in the small-$x$ region.%

The sea-antiquark distributions $\Delta \bar{u}$ and $\Delta \bar{d}$ do not present relevant differences in terms of precision. The central value $\Delta \bar{u}$ receives a small upward shift at NNLO, whereas the central value of $\Delta \bar{d}$ remains almost unchanged.%

The major differences are observed in the case of the strange distributions $\Delta s$ and $\Delta \bar{s}$. The NNLO fit introduces a notable downward shift in the central-$x$ region for the central values of both strange distributions. The uncertainty generally reduces for $\Delta s$ in the small- to medium-$x$ region, but are almost unchanged for $\Delta \bar{s}$.%

In conclusion, the impact of perturbative corrections is generally moderate, except for $\Delta g$, $\Delta s$, and $\Delta \bar{s}$. The former presents a remarkable uncertainty reduction, while the latter are moved close to the behaviour of a DIS-only fit. The other distributions receive small enhancements in terms of accuracy, and the central values remain almost comparable between the two perturbative orders.
%The higher value of the global $\chi^2$ at NNLO can be ascribed to the fact that the analysis makes use of assumption $\Delta s = \Delta \bar{s}$. If true, this would indicate that NNLO corrections bear different information for $\Delta s$ and $\Delta \bar{s}$ separately. Hence, further studies should be carried out by relaxing this assumption and assessing the impact of independent parametrisations of the strange distributions.

%____________________________________________________
\subsection{Impact of theoretical assumptions}
%
\afterpage{
  \begin{figure}[]
    \centering
    \includegraphics[width=\textwidth]{Chapters/Chapter_4/figs/a3_a8.pdf}
    \caption{\small{Comparison of the \texttt{MAPpol1.0} baseline set at NNLO with and without including sum rules $a_3$ and $a_8$ in the data set. Parton distributions are displayed in flavour basis at $\mu_0 = 1 \, \T{GeV}$ as functions of $x$. For each flavour, the absolute values of the distributions are displayed in the upper panel and their ratio to the baseline (BL) in the lower one. Uncertainties correspond to $1 \, \sigma$.}}
    \label{fig:a3_a8_nnlo}
  \end{figure}
  \clearpage
}

\begin{table}[t!]
  \centering
  \small
  \input{tables/a3_a8.tex}
  \caption{
    \small
    Global $\chi^2$ and predictions of $a_3$ and $a_8$ for the two configurations w/ and w/o the sum rules constraint. The values are presented for both NLO and NNLO determinations.
  \label{tab:a3_a8_nnlo}}
\end{table}

The results presented in this Thesis have been obtained with a number of theoretical and methodological constraints, as discussed earlier. As a consequence, the parameter space is reduced, as the allowed functional forms are only those compatible with the assumptions. Still, one must verify that this functional space is consistent with that enabled by experimental data and, to do so, I now study the stability of the results upon variation of some of these assumptions.

%______________________
\subsection*{Sum rules}
The baseline fit \texttt{MAPpol1.0} includes the sum rules $a_3$ and $a_8$ as part of the data set. In order to assess the impact of these two additional points, I performed two more PDF determinations at NLO and NNLO using the same baseline configuration of Tab.~\ref{tab:baseline}, but without the sum rules constraint. For the NNLO perturbative order, comparison is displayed in Fig.\ref{fig:a3_a8_nnlo}. The corresponding values of the global $\chi^2$ for the constrained and unconstrained fits, as well as the prediction of the moments of $\Delta T_3$ and $\Delta T_8$ distributions, are presented in Tab.~\ref{tab:a3_a8_nnlo}, also for the NLO fit.%

At NNLO, a small deterioration of the fit quality figures in the constrained determination. The inspection of Fig.~\ref{fig:a3_a8_nnlo} leads to the conclusion that, in general, the impact on helicity PDFs from constraining $a_3$ and $a_8$ is small, except for the gluon and sea quark distributions. Moreover, the predictions reported in Tab.~\ref{tab:a3_a8_nnlo} for the NNLO case are in agreement within uncertainties. Thus, at least at NNLO, the assumption of exact $SU(2)_f$ and $SU(3)_f$ symmetries is compatible with the data included in the fit.%

At NLO, the fit quality is unaffected by including the constraint, as shown in Tab.~\ref{tab:a3_a8_nnlo}. The values of $a_3$ and $a_8$ are recovered by the unconstrained distribution, although the moment of the octet is affected by a huge uncertainty.%

In conclusion, at both NLO and NNLO the exact $SU(2)_f$ and $SU(3)_f$ symmetries are compatible with the included data.

%_______________________
\subsection*{Positivity}

\afterpage{
\begin{figure}[b]
  \centering
  \includegraphics[width=\textwidth]{Chapters/Chapter_4/figs/positivity.pdf}
  \caption{\small{Comparison of the baseline \texttt{MAPpol1.0} fit at NNLO (orange) with the same set without imposing positivity (blue). Parton distributions are displayed in flavour basis at $\mu_0 = 1 \, \T{GeV}$ as functions of $x$.}}
  \label{fig:positivity}
\end{figure}
\clearpage
}
The baseline configuration exploits positivity of the individual cross-sections entering the polarised asymmetries to impose the leading order constraint, Eq.~\eqref{eq:positivity_fl}, to each parametrised flavour separately, by using the \texttt{NNPDF31\_nnlo\_pch\_as\_0118} set ~\cite{NNPDF:2017mvq}. The constraint is implemented analytically as a transformation in the last layer of the neural network according to Eq.~\eqref{eq:pos_net}.%

In order to assess the effect of the positivity constraint, I performed another fit where the positivity has been imposed as in Eq.~\eqref{eq:positivity_fl_sigma}, but with an inflated value of the standard deviation. In particular, the constraint has been relaxed to $50 \, \sigma$, which is equivalent to remove the positivity constraint altogether. The parton distributions thus obtained are compared with the baseline fit and displayed in Fig.~\ref{fig:positivity} at NNLO. The values of the global $\chi^2$ are reported in Tab.~\ref{tab:positivity}.%

\begin{table}[t]
  \centering
  \small
  \input{tables/positivity.tex}
  \caption{
    \small
    Values of the global $\chi^2$ per data point for the baseline fit and the configuration with the positivity constrained relaxed to $50 \, \sigma$, both at NNLO.}
  \label{tab:positivity}
\end{table}
%%

The fit quality receives no significant variations, with only a moderate improvement in the global $\chi^2$ when the constraint is relaxed. As in the case of the sum rules, this indicates that the parametrisation is flexible enough to enclose the positivity, and the deterioration of the fit quality is then ascribed to the reduction of the functional space caused by the constraint. In terms of PDFs, these are significantly affected by the positivity bound, in particular in the large-$x$ region, where the presence of data is scarce. Hence, the inclusion of the positivity constraint has a strong impact on the distributions, and guarantees that cross-sections are positive.
%However, it must be observed that the effects of the positivity bounds on parton distributions at small-$x$ region are not significant, given the LO and NLO positivity bounds differ significantly in this region \cite{Altarelli:1998gn}. Thus, the results of the baseline \texttt{MAPpol1.0} should be considered reliable out of the extrapolation region at small-$x$.

%____________________________________
\subsection{Impact of data}
\label{sec:study_data}

In \secref{sec:nnlo} I pointed out that, in terms of global $\chi^2$, the determination at NNLO obtained with the baseline configuration performed worse than that carried out at NLO, and that a similar deterioration figures also in some individual data sets. I now start out where I left off, and I draw the focus of this section on the possible effects that different choices of data sets may have on the observed discrepancy.%

First, I compute the difference of the global $\chi^2$ between NLO and NNLO in unit of $\sigma_{\chi^2}$, so that different values can be compared each other:
%
\begin{equation}
  \Delta \chi^2 \equiv \frac{\chi^2_{\T{NNLO}} - \chi^2_{\T{NLO}}}{\sigma_{\chi^2}}\,.
  \label{eq:delta_chi2}
\end{equation}
%
Here, $\sigma_{\chi^2}$ is the square root of the variance of the $\chi^2$ distribution, defined as
%
\begin{equation}
  \sigma_{\chi^2} = \sqrt{2 N_{\T{dat}}}\,.
\end{equation}
%
It is worth noting that the $\chi^2$ that enters Eq.~\eqref{eq:delta_chi2} is not divided by the number of data points $N_{\T{dat}}$.%

Now that I have defined these statistical quantities, the next step is to choose which individual sets should be removed from the global data set. As I already mentioned in \secref{sec:nnlo}, most of SIDIS data are affected by notable deteriorations of the fit quality at NNLO, in particular those of HERMES. Moreover, Tab.~\ref{tab:nnlo_nlo_chi2} shows that the $\chi^2$ of the sum rules is much higher at NNLO than at NLO. These observations yield the question whether HERMES data and sum rules may be a cause of the observed deterioration. For that reason, I performed two more fits with variations from the baseline configuration - one neglects sum rules, while the other removes HERMES's SIDIS data as well as sum rules too. Furthermore, JLAB data are characterised by a higher precision if compared to the other measurements, and such a non-uniformity might contribute negatively to the convergence of the $\chi^2$ at NNLO. Hence, a fourth data configuration is considered, which removes JLAB and HERMES SIDIS data, together with the sum rules. Finally, a fifth fit is performed by removing SIDIS data altogether, yet maintaining sum rules and imposing $\Delta s = \Delta \bar{s}$.%

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{Chapters/Chapter_4/figs/chi2_discrepancy.pdf}
  \caption{\small{(Left) values of the global $\chi^2 / N_{\T{dat}}$ for different data configurations at both NNLO and NLO. (Right) $\chi^2$ discrepancies measured as in Eq.~\eqref{eq:delta_chi2}, for each data configuration.}}
  \label{fig:discrepancy}
\end{figure}

The global (reduced) $\chi^2$ for the aforementioned configurations at both perturbative orders and the related discrepancy measured by means of Eq.~\eqref{eq:delta_chi2} are shown in Fig.~\ref{fig:discrepancy} on the left and right side, respectively. Overall, the baseline configuration accounts for the highest discrepancy ($2.20$), which slightly reduces when the sum rules constraint is removed ($1.71$). The discrepancy drops when HERMES' SIDIS data are removed, reaching $0.93$. However, when JLAB data are also neglected the discrepancy rises to $1.33$, still remaining under the beseline configurations with and without sum rules. Finally, the configuration without SIDIS data amounts to $0.40$, thus figuring as the lowest value among all the scores. From this investigation, it comes out that SIDIS measurements contribute the most to the discrepancy, and that this may be caused by SIDIS data from HERMES. On the other hand, removing JLAB data does not bring to any enhancement, contrary to the prior anticipations.% 

%_________________________________________________
\subsection{Comparison with other PDF sets}

In Fig.~\ref{fig:competitors} I compare the PDFs obtained at NLO from the baseline fit, \texttt{MAPpol1.0}, to other available PDF sets from \texttt{NNPDFpol1.1}~\cite{Nocera:2014gqa}, \texttt{JAM17}~\cite{Ethier:2017zbq} and \texttt{DSSV}~\cite{DeFlorian:2019xxt}, all accurate to NLO. Here I present a brief summary of the main features that characterise each of these sets:
%%
\begin{itemize}
  \item[] \texttt{\textbf{NNPDFpol1.1}} The parton set is obtained using inclusive DIS data. Other experimental information coming from open-charm production in fixed-target DIS, and jet and $W$ production in proton-proton collisions are then included in the PDF ensemble via Bayesian reweighting and unweighting \cite{Ball:2011gg, Ball:2010gb}. The functional parametrisation is given by a set of neural networks, one for each parametrised distribution. The architecture is wider than that presented in this Thesis, with two deep-layers inside. Moreover, the parametrisation is supplied with two preprocessing functions accounting for the small- and large-$x$ behaviours. The uncertainties are estimated with the Monte Carlo sampling method. On the side of theoretical assumptions, this set imposes positivity \eqref{eq:positivity_fl} and sum rules \eqref{eq:a3_a8_values} during the minimisation procedure through normalisation coefficients that are fitted to data. 
  \item[] \texttt{\textbf{JAM17}} This set uses data from inclusive and semi-inclusive DIS, together with single-inclusive $e^+ e^-$ annihilation data. This set is obtained by performing a simultaneous fit of both PDFs and FFs. Both are parametrised in terms of Euler-Beta functions. This set does not include positivity nor assumptions about $SU(2)_f$ and $SU(3)_f$ symmetries. Also in this case, uncertainties have been estimated by means of Monte Carlo sampling.
  \item[] \texttt{\textbf{DSSV}} The set takes into account data from inclusive and semi-inclusive polarised DIS, as well as from polarised $pp$ scattering at RHIC. These include jet production $pp \rightarrow \T{jets} + X$, and $\pi^0$ production $pp \rightarrow \pi^0 + X$. The parametrisation is given by polynomial. Two more free parameters are used to account for deviations from the assumption of exact $SU(2)_f$ and $SU(3)_f$ symmetries, and positivity bounds are also imposed to parton distributions. The estimate of the uncertainties is based on the use of Lagrange multipliers, as described in Ref.~\cite{Stump:2001gu}.
\end{itemize}
%%

\afterpage{
  \begin{figure}
    \centering
    \includegraphics[width=\textwidth]{Chapters/Chapter_4/figs/competitors.pdf}
    \caption{\small{Comparison of the \texttt{MAPpol1.0}, \texttt{NNPDFpol1.1}~\cite{Nocera:2014gqa}, \texttt{JAM17}~\cite{Ethier:2017zbq} and \texttt{DSSV}~\cite{DeFlorian:2019xxt} sets. The distributions are displayed at $\mu_0 = 1 \, \T{GeV}$ in flavour basis.}}
    \label{fig:competitors}
  \end{figure}
  \clearpage
}

The main observations coming from inspection of Fig.~\ref{fig:competitors} are summarised below:
\begin{itemize}
  \item In the case of $\Delta g$, it is clear that the inclusion of gluon initiated-processes has a remarkable impact on the final results, as the determinations from \texttt{NNPDFpol1.1} and \texttt{DSSV} show. Indeed, these distributions are in highly agreement between them, although the former provides a more conservative uncertainty estimate for $x \lesssim 0.1$. The lack of jet production data in \texttt{MAPpol1.0} is more evident in the middle-$x$ region, where the behaviour of the gluon slightly changes if compared to \texttt{NNPDFpol1.1} and \texttt{DSSV}. Nevertheless, both are within the \texttt{MAPpol1.0} uncertainties. The same does not hold for the gluon from \texttt{JAM17}, whose differences in the middle-$x$ region are not contained in the \texttt{MAPpol1.0} bounds. However, the agreement is then restored in the large-$x$ region, where \texttt{MAPpol1.0} is in broad agreement with the other sets.
  \item The valence quark distributions $\Delta u$ and $\Delta d$ from \texttt{MAPpol1.0} are in very good agreement with the corresponding distributions from the other available sets. For $x \lesssim 0.01$, where experimental data is sparse (see Fig.~\ref{fig:kin_cov}), the relative uncertainty on both $\Delta u$ and $\Delta d$ distributions from \texttt{MAPpol1.0} is larger than that of the corresponding distributions from \texttt{NNPDFpol1.0}, \texttt{JAM17} and \texttt{DSSV}. On the other hand, at large-$x$ the uncertainty reduces and becomes comparable to that of the other PDF sets.
  \item In the case of $\Delta \bar{u}$ and $\Delta \bar{d}$ distributions there is a good agreement at large $x$ with all the other determinations. In general, the \texttt{MAPpol1.0} is affected by a larger uncertainty, especially for $x \lesssim 0.01$, where DIS and SIDIS data is scarce. This is a consequence of the fact that \texttt{MAPpol1.0} does not include data from proton-proton collisions, whereas \texttt{DSSV} and \texttt{NNPDFpol1.1} do. Hence, their distributions have generally smaller uncertainties in this region thanks to $pp$ processes (\textit{e.g.} Drell-Yan or $W$ production), which provide more information on quark-antiquark. On the other hand, the distributions from \texttt{JAM17}, which do not include proton-proton collisions, are affected by smaller uncertainties than \texttt{MAPpol1.0}.
  \item The $\Delta s$ and $\Delta \bar{s}$ distributions from \texttt{MAPpol1.0} receive their major contributions from SIDIS data and the axial moment $a_8$. Both \texttt{NNPDFpol1.1} and \texttt{DSSV} determinations include data from $pp$ collisions, and exploit $SU(3)_f$ symmetry. Still, within the region $0.03 \lesssim x \lesssim 0.1$ figures a discrepancy which is not included in the relative uncertainty bounds. Nevertheless, the \texttt{MAPpol1.0} determination is compatible with both of them. On the other hand, the uncertainty of \texttt{JAM17} is much more conservative than the uncertainties of the corresponding distributions from \texttt{MAPpol1.0}, \texttt{NNPDFpol1.1} and \texttt{DSSV}, maybe due to the lack of SIDIS data.
\end{itemize}
%%


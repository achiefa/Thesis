\chapter{Linear Systems}
\label{app:lin_sys}

In linear algebra, the Cholesky decomposition (or factorization) decomposes an hermitian, positive-definite matrix into a product between a lower triangular matrix and its conjugate. The formulation of the Cholesky decomposition requires some basic concepts in linear systems, that I shall briefly review. I follow Ref.~\cite{GoluVanl96}, where the reader can find an extended discussion of the arguments presented here.

\section{Triangular Systems}
The problem of finding a solution for a linear system $\mb{V} \cdot \mb{x} = \mb{b}$ appears frequently when dealing with numerical computation. Gaussian elimination provides an efficient way to solve such systems by converting the  original system into an equivalent triangular one. Thus, it is worth spending some words to outline basic properties and relations about triangular systems.%

Let us consider a linear system written in matrix notation
%%
\begin{equation}
    \mb{L} \cdot \mb{x} = \mb{b} \hspace{10mm} \textrm{or} \hspace{10mm} \mb{U} \cdot \mb{x} = \mb{b} \; ,
\end{equation}
%%
where $\mb{L}$ and $\mb{U}$ are lower and upper triangular matrices respectively. These systems can be solved in $\mb{x}$ by means of an iterative process called \textit{forward substitution} for lower triangular matrices and \textit{backward substitution} for upper triangular matrices. 


\subsection*{Forward and Backward Substitution}
Given a lower triangular matrix $\mb{L} \in \mathbb{R}^{m \times m}$, the matrix equation $\mb{L} \cdot \mb{x} = \mb{b}$ can be written as a system of n linear equations
%%
\begin{equation}
\begin{matrix}
  \ell_{1,1} x_1 &   &                &   &        &   &                & = &    b_1 \\\\
  \ell_{2,1} x_1 & + & \ell_{2,2} x_2 &   &        &   &                & = &    b_2 \\\\
          \vdots &   &         \vdots &   & \ddots &   &                &   & \vdots \\
  \ell_{m,1} x_1 & + & \ell_{m,2} x_2 & + & \dotsb & + & \ell_{m,m} x_m & = &    b_m \\
\end{matrix}
\end{equation}
%%
The first equation does only involve $x_1$ and can be solved by simply inverting the relation. One can then substitute $x_1$ into the second equation and solve for $x_2$. By iterating this method, one finds the solution for each variable which takes the form
%%
\begin{equation}
    x_i = \frac{b_i - \sum_{j=1}^{i-1}\ell_{i,j}\,x_j}{\ell_{i,i}}\,, \hspace{10mm} i=1, \dots, m\,.
\end{equation}
%%
Thus, given a linear triangular system with $m$ equations, the algorithm requires $\mathcal{O}(m)$ steps to find the complete set of solutions. The same arguments hold for the backward substitution, provided that the procedure is inverted.

\subsection*{The LU factorisation}
It can be shown that if a matrix $\mb{V} \in \mathbb{R}^{m\times m}$ is nonsingular (\textit{i.e.}, $\det (V) \neq 0$), then it is possible to implement an algorithm that computes a unit lower triangular matrix $\mb{L} \in \mathbb{R}^{m\times m}$ ($\det (\mb{L}) =1$) and an upper triangular matrix $\mb{U} \in  \mathbb{R}^{m\times m}$ such that 
%%
\begin{equation}
    \mb{V} = \mb{L} \mb{U} 
    \label{eq:LU_dec}
\end{equation}
%%
and $\det\left( \mb{V} \right) = u_{1,1} \, u_{2,2} \, \dots \, u_{n,n} $. Eq.~\eqref{eq:LU_dec} is also known as LU decomposition (or factorisation) and provides the building block for the Cholesky decomposition.

\section{Symmetries and the Cholesky decomposition}
When dealing with numerical analysis, it can be fruitful to exploit symmetries and properties whenever they are present. If $\mb{V} \in \mathbb{R}^{m\times m}$ is a symmetric matrix and admits LU decomposition, $\mb{V} = \mb{L} \mb{U}$, then $\mb{L}$ and $\mb{U}$ are related. In particular, it can be proved that $\mb{U} = \mb{D} \mb{L}^T$, where $\mb{D} \in \mathbb{R}^{m \times m}$ is a diagonal matrix. Thus, the matrix $\mb{V}$ admits the following decomposition
%%
\begin{equation}
    \mb{V} = \mb{L} \mb{D} \mb{L}^T \;,
\end{equation}
%%
which is also unique. If in addition the matrix $\mb{V}$ is also positive definite\footnote{\footnotesize{Note that this is the case of the covariance matrix defined in \chapref{ch:4}}} (that is, $\mb{x}^T \mb{V} \mb{x} > 0$ for all non-zero $\mb{x} \in \mathbb{R}^{m}$), then also the diagonal matrix $\mb{D}$ is so\footnote{\footnotesize Indeed, if $\mb{V}$ is positive definite and $\mb{L}$ has full rank, then $\mb{D} = \mb{L}^{-1} \mb{D} \mb{L}^{T -1}$ is also positive definite.}. This means that all diagonal entries are positive and thus one can define the matrix
%%
\begin{equation}
    \mb{G} = \mb{L} \sqrt{\mb{D}} = \mb{L} \; \T{diag}(\sqrt{d_1},\dots, \sqrt{d_{n}})\,,
\end{equation}
%%
which is a lower triangular matrix with positive diagonal entries and such that $\det (\mb{G}) = \det (\mb{D}) > 0$. It is then easy to show that $\mb{V}$ satisfies the so-called \textit{Cholesky} decomposition
%%
\begin{equation}
    \mb{V} = \mb{L} \sqrt{\mb{D}} \sqrt{\mb{D}} \mb{L}^T = \left( \mb{L} \sqrt{\mb{D}} \right) \left( \mb{L} \sqrt{\mb{D}} \right)^{T} = \mb{G} \mb{G}^{T} \,,
\end{equation}
%%
where the matrix $\mb{G} = \mb{L} \sqrt{\mb{D}}$ is named \textit{Cholesky factor} and its entries can be computed recursively as follows
%%
\begin{align}
    &G_{ii} = \sqrt{V_{ii} - \sum_{k=1}^{i-1} G_{ik}^2}\,,\\[10pt]
    & G_{ij} = \frac{1}{G_{jj}} \left[ \mb{V}_{ij} - \sum_{k=1}^{j-1} G_{ik} G_{jk}\right] \hspace{5mm} \textrm{for} \hspace{5mm} i>j \,,\\[10pt]
    &G_{ij} = 0 \hspace{5mm} \textrm{for} \hspace{5mm} i<j \, .
\end{align}
%%
The Cholesky decomposition can be used to solve linear system described by a positive definite, symmetric matrix $\mb{V}$. Indeed, the solution of the system
%%
\begin{equation}
    \mb{V} \cdot \mb{x} = \mb{G} \mb{G}^T = \mb{b} 
    \label{eq:app:original_sys}
\end{equation}
%%
is decomposed into two distinct triangular systems that can be solved through forward substitution. To see this, I introduce the vector $\mb{y}$ such that
%%
\begin{equation}
    \mb{G}^T \mb{x} = \mb{y} \;.
    \label{eq:app:triangular_1}
\end{equation}
%%
The original system Eq.~\eqref{eq:app:original_sys} can then be recast as
%%
\begin{equation}
    \mb{G} \mb{y} = \mb{b} \;,
    \label{eq:app:triangular_2}
\end{equation}
%%
which can be solved for $\mb{y}$ via forward substitution (recall that $\mb{G}$ is a lower triangular matrix). The solution can then be substituted into Eq.~\eqref{eq:app:triangular_1} so that
%%
\begin{equation}
    \mb{G}^T \mb{x} = \mb{y} \;,
\end{equation}
%%
which can be solved for $\mb{x}$ by applying forward substitution, thus solving the original linear system Eq.~\eqref{eq:app:original_sys}.%

The tools I have discussed are implemented in common and useful libraries, such as the \texttt{GNU} Scientific Library, which is included in \texttt{Denali}.